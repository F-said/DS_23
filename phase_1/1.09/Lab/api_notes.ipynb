{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time & Space Complexity Review\n",
    "\n",
    "Create a function that searches through a list of letters and checks if a target letter exists within the list. Utilize the linear search or binary search examples from before.\n",
    "\n",
    "What is the time and space complexity of your algorithm in the worst-case?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def searcher(letters, l):\n",
    "    # write solution here\n",
    "    pass\n",
    "\n",
    "print(searcher([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"], \"f\"))\n",
    "print(searcher([\"a\", \"b\", \"c\", \"d\", \"e\", \"f\", \"g\", \"h\"], \"b\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests & API Review\n",
    "\n",
    "Create an API call using [SWAPI](https://swapi.dev/) to print out the URL of the planets involved in Star Wars Episode 4 (https://swapi.dev/dev/films/1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "# write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "how can we use this list of URL's to print out the name of each planet in Star Wars Episode 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requests\n",
    "\n",
    "So far we’ve been using the `requests` module to get data from a URL, but what are we really doing?\n",
    "\n",
    "We are getting a resource from the internet using HTTP requests\n",
    "https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview \n",
    "\n",
    "We can use `requests` to get data from a web-page. Traditionally we do this over our browser.\n",
    "\n",
    "But we can also accomplish this via Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "r = requests.get(\"https://www.theknowledgehouse.org/\")\n",
    "r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As data engineers and analysts, we want to practice our skills in getting data from an API (or “extracting”), which we will then transform and load\n",
    "\n",
    "This is known as the ETL (Extract-Transform-Load) process.\n",
    "\n",
    "We use an API to “request” data (using the requests module) so that we can begin the very first step of the ETL process.\n",
    "\n",
    "This is often only one of the data sources that we query. We will learn about & review the following methods as well:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice Problem\n",
    "\n",
    "We can then tie in other concepts to accomplish a variety of tasks.\n",
    "\n",
    "Let’s say we want to create a new CSV file of 10 star wars planets & their climates\n",
    "\n",
    "Firstly let’s consider, which modules do we need to request our data & then save it into a csv file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just mimicked the ETL process!\n",
    "\n",
    "We extracted data from a resource\n",
    "We structured it to fit our restrictions\n",
    "We didn’t really load anything, but we could use the CSV file to make interesting analysis! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "\n",
    "headers = [\"name\", \"climate\"]\n",
    "list_data = []\n",
    "\n",
    "for i in range(1, 10):\n",
    "    r = requests.get(f\"https://swapi.dev/api/planets/{i}\")\n",
    "    data = r.json()\n",
    "    name = data[\"name\"]\n",
    "    climate = data[\"climate\"]\n",
    "\n",
    "    # how can we make a dictionary of name and climate keys?\n",
    "    pdata = {\"name\": name, \"climate\": climate}\n",
    "    list_data.append(pdata)\n",
    "\n",
    "with open(\"sw_planets.csv\", \"w\", newline='') as outfile:\n",
    "    writer = csv.DictWriter(outfile, fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(list_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stock API\n",
    "\n",
    "Use an API to load data.\n",
    "Use the csv module to write data\n",
    "Use base-Python to analyze data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'OK', 'from': '2022-11-08', 'symbol': 'AAPL', 'open': 140.41, 'high': 141.43, 'low': 137.49, 'close': 139.5, 'volume': 89908477.0, 'afterHours': 139.98, 'preMarket': 139.04}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "key=\"\"\n",
    "\n",
    "stock = \"AAPL\"\n",
    "date = \"2022-11-08\"\n",
    "\n",
    "open_close = f\"v1/open-close/{stock}/{date}?adjusted=True\"\n",
    "r = requests.get(f\"https://api.polygon.io/{open_close}&apiKey={key}\")\n",
    "\n",
    "print(r.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
